import { create } from 'zustand'
import { invoke } from '@tauri-apps/api/core'
import { writeText } from '@tauri-apps/plugin-clipboard-manager'
import { getCurrentWindow } from '@tauri-apps/api/window'
import { useSettingsStore } from './settingsStore'
import { AudioCapture, AudioConverter } from '../lib/audioCapture'
import { audioFeedback } from '../lib/audioFeedback'
import type { InlineToastType } from '../components/InlineToast'

export type RecordingState = 'idle' | 'recording' | 'processing' | 'error'
export type OperationMode = 'direct' | 'preview'

// æ°”æ³¡æç¤ºçŠ¶æ€
export interface ToastState {
  type: InlineToastType
  message: string
  dismissible: boolean // æ˜¯å¦å¯æ‰‹åŠ¨å…³é—­
  duration: number // è‡ªåŠ¨æ¶ˆå¤±æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰ï¼Œ0 è¡¨ç¤ºä¸è‡ªåŠ¨æ¶ˆå¤±
}

// æ‰©å±• Window æ¥å£ä»¥æ”¯æŒè‡ªå®šä¹‰å±æ€§
declare global {
  interface Window {
    __recordingTimer?: number
  }
}

// ğŸ”¥ å¼•æ“åˆå§‹åŒ–ç¼“å­˜ï¼šè®°å½•å·²åˆå§‹åŒ–çš„å¼•æ“å’Œæ¨¡å‹ï¼Œé¿å…é‡å¤åˆå§‹åŒ–
// æ ¼å¼: { engineType: modelName } ä¾‹å¦‚: { whisper: 'base', funasr: 'paraformer-zh' }
const engineInitCache: { [key: string]: string } = {}

interface RecordingStore {
  state: RecordingState
  duration: number
  transcription: string | null
  transcribedText: string // New: Current transcribed text for display
  error: string | null
  audioLevel: number
  operationMode: OperationMode // å½“å‰æ“ä½œæ¨¡å¼
  audioCapture: AudioCapture | null // å‰ç«¯éŸ³é¢‘é‡‡é›†å®ä¾‹

  // æ°”æ³¡æç¤ºçŠ¶æ€
  toast: ToastState | null
  isFirstRecording: boolean // æ˜¯å¦é¦–æ¬¡å½•éŸ³ï¼ˆç”¨äºé¦–æ¬¡åˆå§‹åŒ–æç¤ºï¼‰
  hasShownLongAudioTip: boolean // æ˜¯å¦å·²æ˜¾ç¤ºé•¿éŸ³é¢‘æç¤º

  // Actions
  prewarmRecording: () => Promise<void> // é¢„çƒ­ï¼šæå‰åˆå§‹åŒ– getUserMedia
  startRecording: (skipBackendCall?: boolean, cachedInstance?: AudioCapture | null) => Promise<void>
  stopRecording: () => Promise<void>
  cancelRecording: () => void
  setAudioLevel: (level: number) => void
  resetState: () => void
  setOperationMode: (mode: OperationMode) => void

  // New text actions
  clearText: () => void
  copyText: () => Promise<void>
  insertText: () => Promise<void>
  setTranscribedText: (text: string) => void

  // Toast actions
  showToast: (
    type: InlineToastType,
    message: string,
    dismissible?: boolean,
    duration?: number,
  ) => void
  clearToast: () => void
}

export const useRecordingStore = create<RecordingStore>((set, get) => ({
  state: 'idle',
  duration: 0,
  transcription: null,
  transcribedText: '',
  error: null,
  audioLevel: 0,
  operationMode: 'preview', // é»˜è®¤é¢„è§ˆæ¨¡å¼
  audioCapture: null, // éŸ³é¢‘é‡‡é›†å®ä¾‹
  toast: null,
  isFirstRecording: true,
  hasShownLongAudioTip: false,

  prewarmRecording: async () => {
    console.log('[RecordingStore] ğŸ”¥ğŸ”¥ğŸ”¥ ========== PREWARM RECORDING CALLED ==========')

    try {
      // ğŸ”‘ å…³é”®ï¼šæ£€æŸ¥æ˜¯å¦å·²ç»åœ¨å½•éŸ³æˆ–å·²æœ‰å®ä¾‹
      const currentState = get().state
      const existingCapture = get().audioCapture

      if (currentState === 'recording' || existingCapture) {
        console.log('[RecordingStore] âš ï¸  Already recording or instance exists, skipping prewarm')
        console.log('[RecordingStore] State:', currentState, 'Has instance:', !!existingCapture)
        return
      }

      // ğŸ”‘ å…³é”®ä¿®å¤ï¼šå…ˆæ¸…ç†æ‰€æœ‰å¯èƒ½æ³„æ¼çš„æ—§å®ä¾‹ï¼ˆä»…åœ¨ idle çŠ¶æ€ï¼‰
      AudioCapture.cleanupAllInstances()

      // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
      if (!AudioCapture.isSupported()) {
        throw new Error('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å½•åˆ¶åŠŸèƒ½ã€‚è¯·ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬çš„æµè§ˆå™¨ã€‚')
      }

      // åˆ›å»ºéŸ³é¢‘é‡‡é›†å®ä¾‹
      console.log('[RecordingStore] Step 1: Creating AudioCapture instance...')
      const audioCapture = new AudioCapture({
        sampleRate: 16000,
        channelCount: 1,
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true,
      })

      // ğŸ”¥ é¢„çƒ­ï¼šåˆå§‹åŒ– getUserMedia å’Œ MediaRecorderï¼Œä½†ä¸å¼€å§‹å½•éŸ³
      console.log(
        '[RecordingStore] Step 2: Prewarming AudioCapture (getUserMedia + MediaRecorder)...',
      )
      try {
        await audioCapture.prewarm()
        console.log('[RecordingStore] ğŸ”¥âœ…âœ…âœ… Prewarm completed! Ready to record instantly!')
      } catch (error) {
        // å¤„ç†æƒé™è¢«æ‹’ç»çš„æƒ…å†µ
        if (error instanceof Error && error.name === 'NotAllowedError') {
          console.error('[RecordingStore] âŒ Microphone permission denied during prewarm')
          set({
            state: 'error',
            error: 'âŒ éº¦å…‹é£æƒé™æœªæˆæƒ\\n\\nè¯·åœ¨æµè§ˆå™¨ä¸­å…è®¸è®¿é—®éº¦å…‹é£ï¼Œç„¶åé‡è¯•ã€‚',
          })
          throw new Error('Microphone permission denied')
        }
        throw error
      }

      // ä¿å­˜é¢„çƒ­çš„å®ä¾‹
      console.log('[RecordingStore] Step 3: Saving prewarmed instance...')
      set({ audioCapture: audioCapture })
      console.log('[RecordingStore] ğŸ”¥ Prewarmå®Œæˆï¼Œå®ä¾‹å·²ä¿å­˜ï¼Œç­‰å¾… startRecording è°ƒç”¨')
    } catch (error) {
      console.error('[RecordingStore] Prewarm failed:', error)
      set({ state: 'error', error: String(error) })
    }
  },

  startRecording: async (skipBackendCall = false, cachedInstance = null) => {
    console.log('ğŸ¤ğŸ¤ğŸ¤ [RecordingStore] ========== START RECORDING CALLED ==========')
    console.log('[RecordingStore] Has cached instance from component:', !!cachedInstance)

    // ğŸš€ CRITICAL FIX: ç«‹å³æ£€æŸ¥å¹¶è®¾ç½®çŠ¶æ€ï¼Œé˜²æ­¢å¹¶å‘è°ƒç”¨
    const currentState = get().state
    if (currentState === 'recording') {
      console.log('[RecordingStore] âš ï¸  Already recording, ignoring duplicate call')
      return
    }

    console.log('[RecordingStore] skipBackendCall:', skipBackendCall)

    try {
      console.log('[RecordingStore] Starting recording...')

      // ğŸ”¥ ä¼˜å…ˆçº§ç­–ç•¥ï¼š
      // 1. ä¼˜å…ˆä½¿ç”¨ç»„ä»¶ä¼ å…¥çš„ç¼“å­˜å®ä¾‹ï¼ˆAudioCacheManagerï¼‰
      // 2. å…¶æ¬¡ä½¿ç”¨ store ä¸­ä¿å­˜çš„é¢„çƒ­å®ä¾‹ï¼ˆæ—§çš„ prewarmRecordingï¼‰
      // 3. æœ€åè¿›è¡Œå†·å¯åŠ¨åˆ›å»ºæ–°å®ä¾‹
      let audioCapture = cachedInstance || get().audioCapture
      if (audioCapture) {
        const source = cachedInstance
          ? 'AudioCacheManager (component-level)'
          : 'store prewarmRecording'
        console.log(
          `[RecordingStore] âš¡âš¡âš¡ Using cached AudioCapture from ${source} - INSTANT START!`,
        )
        // ç›´æ¥å¼€å§‹å½•éŸ³ï¼ˆMediaRecorder å·²ç»å°±ç»ªï¼‰
        await audioCapture.start()
        console.log('[RecordingStore] âœ…âœ…âœ… Recording started instantly (cached)!')
      } else {
        console.log('[RecordingStore] âš ï¸  No cached instance, using cold start...')

        // ğŸ”‘ å…³é”®ä¿®å¤ï¼šæ¸…ç†æ‰€æœ‰å¯èƒ½æ³„æ¼çš„æ—§å®ä¾‹ï¼ˆçƒ­é‡è½½åœºæ™¯ï¼‰
        AudioCapture.cleanupAllInstances()

        // æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦æ”¯æŒ getUserMedia
        if (!AudioCapture.isSupported()) {
          throw new Error('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å½•åˆ¶åŠŸèƒ½ã€‚è¯·ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬çš„æµè§ˆå™¨ã€‚')
        }

        // åˆ›å»ºéŸ³é¢‘é‡‡é›†å®ä¾‹
        console.log('[RecordingStore] Step 1: Creating AudioCapture instance...')
        audioCapture = new AudioCapture({
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        })

        // å¼€å§‹éŸ³é¢‘é‡‡é›†ï¼ˆè¿™ä¼šè§¦å‘æµè§ˆå™¨è¯·æ±‚éº¦å…‹é£æƒé™ï¼‰
        console.log(
          '[RecordingStore] Step 2: Starting audio capture (this will trigger mic permission)...',
        )
        try {
          await audioCapture.start()
          console.log(
            '[RecordingStore] âœ…âœ…âœ… Audio capture started! Microphone indicator should be active!',
          )
        } catch (error) {
          // å¤„ç†æƒé™è¢«æ‹’ç»çš„æƒ…å†µ
          if (error instanceof Error && error.name === 'NotAllowedError') {
            console.error('[RecordingStore] âŒ Microphone permission denied by user')
            const errorMessage = 'éº¦å…‹é£æƒé™æœªæˆæƒ\n\nè¯·åœ¨æµè§ˆå™¨ä¸­å…è®¸è®¿é—®éº¦å…‹é£ï¼Œç„¶åé‡è¯•ã€‚'

            // æ˜¾ç¤ºæƒé™é”™è¯¯æç¤ºï¼ˆä¸¥é‡é”™è¯¯ï¼Œéœ€è¦æ‰‹åŠ¨å…³é—­ï¼‰
            get().showToast('error', errorMessage, true, 0)

            set({
              state: 'error',
              error: `âŒ ${errorMessage}`,
            })
            throw new Error('Microphone permission denied')
          }
          throw error
        }
      }

      // 4. æ£€æŸ¥æ˜¯å¦é¦–æ¬¡å½•éŸ³ï¼Œæ˜¾ç¤ºåˆå§‹åŒ–æç¤º
      const isFirst = get().isFirstRecording
      if (isFirst) {
        console.log('[RecordingStore] First recording detected, showing initialization tip')
        get().showToast('info', 'é¦–æ¬¡å¯åŠ¨éœ€è¦åˆå§‹åŒ–ï¼Œè¯·ç¨å€™...', false, 3000)
      }

      // 5. ä¿å­˜éŸ³é¢‘é‡‡é›†å®ä¾‹å¹¶è®¾ç½®çŠ¶æ€
      console.log('[RecordingStore] Step 3: Setting recording state...')
      set({
        state: 'recording',
        error: null,
        transcription: null,
        duration: 0,
        audioCapture: audioCapture,
        isFirstRecording: false, // æ ‡è®°å·²å®Œæˆé¦–æ¬¡å½•éŸ³
        hasShownLongAudioTip: false, // é‡ç½®é•¿éŸ³é¢‘æç¤ºæ ‡è®°
      })

      // 6. å¯åŠ¨è®¡æ—¶å™¨
      const timer = setInterval(() => {
        set((state) => ({
          duration: state.duration + 0.1,
        }))
      }, 100)

      // Store timer ID for cleanup
      window.__recordingTimer = timer

      console.log(
        '[RecordingStore] ğŸ‰ Recording started successfully using frontend audio capture!',
      )

      // ğŸ”Š æ’­æ”¾å¼€å§‹å½•åˆ¶éŸ³æ•ˆï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡ä¸»æµç¨‹ï¼‰
      audioFeedback.playStart().catch((err) => {
        console.warn('[RecordingStore] Failed to play start sound:', err)
      })
    } catch (error) {
      console.error('[RecordingStore] Failed to start recording:', error)
      set({ state: 'error', error: String(error) })
    }
  },

  stopRecording: async () => {
    try {
      console.log('[RecordingStore] â­â­â­ stopRecording called, current state:', get().state)

      // Clear timer
      if (window.__recordingTimer) {
        clearInterval(window.__recordingTimer)
        delete window.__recordingTimer
      }

      const recordingDuration = get().duration
      console.log('[RecordingStore] ğŸ”µ Setting state to PROCESSING (before transcription)')
      set({ state: 'processing' })
      console.log('[RecordingStore] ğŸ”µ State set to PROCESSING, new state:', get().state)

      // æ£€æŸ¥å½•éŸ³æ—¶é•¿ï¼Œå¦‚æœè¶…è¿‡20ç§’ä¸”æœªæ˜¾ç¤ºè¿‡æç¤ºï¼Œåˆ™æ˜¾ç¤ºé•¿éŸ³é¢‘æç¤º
      const settings = useSettingsStore.getState().settings
      const mode = settings.operationMode || 'preview'
      if (mode === 'direct' && recordingDuration > 20 && !get().hasShownLongAudioTip) {
        console.log('[RecordingStore] Long audio detected (>20s), showing tip')
        // é•¿éŸ³é¢‘æç¤ºä¸è‡ªåŠ¨æ¶ˆå¤±ï¼ˆduration=0ï¼‰ï¼Œç›´åˆ°è½¬å½•å®Œæˆåçª—å£éšè—æ—¶ä¸€èµ·æ¸…é™¤
        get().showToast('info', 'éŸ³é¢‘è¾ƒé•¿ï¼Œè½¬å½•å¯èƒ½éœ€è¦æ›´å¤šæ—¶é—´...', false, 0)
        set({ hasShownLongAudioTip: true })
      }

      // ğŸ¯ æ–°å®ç°ï¼šä»å‰ç«¯éŸ³é¢‘é‡‡é›†è·å–æ•°æ®
      // 1. åœæ­¢å½•éŸ³å¹¶è·å–éŸ³é¢‘æ•°æ®
      const audioCapture = get().audioCapture
      if (!audioCapture) {
        throw new Error('No audio capture instance found')
      }

      console.log('[RecordingStore] Step 1: Stopping audio capture and getting audio data...')
      const audioBlob = await audioCapture.stop()
      console.log('[RecordingStore] âœ… Audio blob received:', audioBlob.size, 'bytes')

      // ğŸ”‘ å…³é”®ä¿®å¤ï¼šstop() ä¼šåœ¨å†…éƒ¨è°ƒç”¨ cleanup()ï¼Œæ‰€ä»¥è¿™é‡Œå¯ä»¥å®‰å…¨åœ°æ¸…é™¤å¼•ç”¨
      // ä½†æˆ‘ä»¬éœ€è¦ç¡®ä¿ stop() å®Œæˆåå†æ¸…é™¤å¼•ç”¨
      console.log('[RecordingStore] âœ… AudioCapture cleanup completed by stop() method')
      set({ audioCapture: null })

      // 2. å°†éŸ³é¢‘è½¬æ¢ä¸º PCM16 æ ¼å¼ï¼ˆåç«¯éœ€è¦çš„æ ¼å¼ï¼‰
      console.log('[RecordingStore] Step 2: Converting audio to PCM16 format...')
      const pcm16Bytes = await AudioConverter.blobToPCM16(audioBlob, 16000)
      console.log('[RecordingStore] âœ… Converted to PCM16:', pcm16Bytes.length, 'bytes')

      // ğŸ¯ å…³é”®ï¼šå°† Uint8Array (å­—èŠ‚) è½¬æ¢ä¸º i16[] (æ ·æœ¬)
      // PCM16 æ˜¯å°ç«¯åºï¼Œæ¯ 2 ä¸ªå­—èŠ‚ç»„æˆä¸€ä¸ª i16 æ ·æœ¬
      const pcm16Samples = new Int16Array(
        pcm16Bytes.buffer,
        pcm16Bytes.byteOffset,
        pcm16Bytes.length / 2,
      )
      console.log(
        '[RecordingStore] âœ… Converted to samples:',
        pcm16Samples.length,
        'samples (',
        (pcm16Samples.length / 16000).toFixed(2),
        'seconds )',
      )

      // 3. ä½¿ç”¨ä¹‹å‰å·²ç»è¯»å–çš„ settingsï¼ˆä¸é‡æ–°åŠ è½½ï¼Œé¿å…ä¸å¿…è¦çš„ç½‘ç»œè¯·æ±‚ï¼‰
      console.log('[RecordingStore] Step 3: Using cached settings...')
      console.log('[RecordingStore] âœ… Using cached settings. Current model:', settings.model)

      // é»˜è®¤ä½¿ç”¨ä¸­æ–‡ï¼Œé™¤éæ˜ç¡®è®¾ç½®ä¸ºå…¶ä»–è¯­è¨€
      let language: string | null = settings.language || 'zh'

      // åªæœ‰åœ¨æ˜ç¡®è®¾ç½®è‡ªåŠ¨æ£€æµ‹ä¸”è¯­è¨€ä¸æ˜¯ä¸­æ–‡æ—¶æ‰ä½¿ç”¨è‡ªåŠ¨æ£€æµ‹
      if (settings.autoDetectLanguage && settings.language !== 'zh') {
        language = null
      } else if (!settings.language || settings.language === 'zh') {
        language = 'zh'
      }

      const modelVersion = settings.model || 'base'

      console.log(
        '[RecordingStore] Step 4: Settings - Model:',
        modelVersion,
        'Language:',
        language || 'auto',
      )
      console.log(
        '[RecordingStore] Auto-detect:',
        settings.autoDetectLanguage,
        'Configured language:',
        settings.language,
      )

      // åˆ¤æ–­æ¨¡å‹ç±»å‹
      const funasrModels = ['paraformer-zh', 'paraformer-large', 'sensevoice-small']
      const isFunASR = funasrModels.includes(modelVersion)

      let transcriptionText: string

      // 4. è°ƒç”¨è½¬å½•
      if (isFunASR) {
        // ğŸ”¥ ç¼“å­˜æ£€æŸ¥ï¼šä»…åœ¨æ¨¡å‹å˜åŒ–æ—¶æ‰é‡æ–°åˆå§‹åŒ–
        const cachedModel = engineInitCache['funasr']
        if (cachedModel !== modelVersion) {
          console.log(
            '[RecordingStore] Step 5: Initializing FunASR engine with model:',
            modelVersion,
          )
          console.log('[RecordingStore] Previous cached model:', cachedModel || 'none')
          try {
            await invoke('initialize_funasr', { modelName: modelVersion })
            engineInitCache['funasr'] = modelVersion // æ›´æ–°ç¼“å­˜
            console.log('[RecordingStore] âœ… FunASR engine initialized and cached')
          } catch (error) {
            console.error('[RecordingStore] Failed to initialize FunASR engine:', error)
          }
        } else {
          console.log('[RecordingStore] âš¡ Using cached FunASR engine (model:', modelVersion, ')')
        }

        // è°ƒç”¨æ–°çš„è½¬å½•å‘½ä»¤ï¼ˆæ¥æ”¶å‰ç«¯éŸ³é¢‘æ•°æ®ï¼‰
        console.log(
          '[RecordingStore] Step 6: Calling transcribe_audio_funasr with frontend audio data...',
        )
        transcriptionText = await invoke<string>('transcribe_audio_funasr', {
          audioData: Array.from(pcm16Samples),
          language: language,
        })
      } else {
        // ğŸ”¥ ç¼“å­˜æ£€æŸ¥ï¼šä»…åœ¨æ¨¡å‹å˜åŒ–æ—¶æ‰é‡æ–°åˆå§‹åŒ–
        const cachedModel = engineInitCache['whisper']
        if (cachedModel !== modelVersion) {
          console.log(
            '[RecordingStore] Step 5: Initializing Whisper engine with model:',
            modelVersion,
          )
          console.log('[RecordingStore] Previous cached model:', cachedModel || 'none')
          try {
            await invoke('initialize_whisper', { modelName: modelVersion })
            engineInitCache['whisper'] = modelVersion // æ›´æ–°ç¼“å­˜
            console.log('[RecordingStore] âœ… Whisper engine initialized and cached')
          } catch (error) {
            console.error('[RecordingStore] Failed to initialize Whisper engine:', error)
          }
        } else {
          console.log('[RecordingStore] âš¡ Using cached Whisper engine (model:', modelVersion, ')')
        }

        // è°ƒç”¨æ–°çš„è½¬å½•å‘½ä»¤ï¼ˆæ¥æ”¶å‰ç«¯éŸ³é¢‘æ•°æ®ï¼‰
        console.log('[RecordingStore] Step 6: Calling transcribe_audio with frontend audio data...')
        transcriptionText = await invoke<string>('transcribe_audio', {
          audioData: Array.from(pcm16Samples),
          language: language,
        })
      }

      console.log('[RecordingStore] âœ… Transcription result:', transcriptionText)
      console.log('[RecordingStore] Transcription result type:', typeof transcriptionText)
      console.log('[RecordingStore] Transcription result length:', transcriptionText?.length)

      // 5. ä¿å­˜è½¬å½•åˆ°æ•°æ®åº“
      console.log('[RecordingStore] Step 5: Saving transcription to database...')
      await invoke('create_transcription', {
        transcription: {
          text: transcriptionText,
          audio_duration: recordingDuration,
          model_version: modelVersion,
          language: language || 'auto',
          created_at: new Date().toISOString(),
          app_context: null,
        },
      })

      // æ ¹æ®æ“ä½œæ¨¡å¼å†³å®šåç»­è¡Œä¸ºï¼ˆä½¿ç”¨ä¹‹å‰å·²è¯»å–çš„ modeï¼‰
      console.log('[RecordingStore] Operation mode from settings:', mode)

      if (mode === 'direct') {
        // ç›´æ¥æ’å…¥æ¨¡å¼ï¼šè½¬å½•å®Œæˆåä¿æŒ processing çŠ¶æ€ï¼Œæ˜¾ç¤º"æ­£åœ¨æ’å…¥..."
        console.log(
          '[RecordingStore] ğŸ”µğŸ”µğŸ”µ Direct mode: keeping processing state for text insertion',
        )
        console.log('[RecordingStore] Transcription text:', transcriptionText)
        set({
          state: 'processing', // ä¿æŒ processing çŠ¶æ€
          transcription: transcriptionText,
          transcribedText: 'æ­£åœ¨æ’å…¥æ–‡æœ¬...', // æ˜¾ç¤ºæ’å…¥ä¸­çš„æç¤º
          duration: 0,
          audioLevel: 0,
        })
        console.log(
          '[RecordingStore] ğŸ”µ State updated, current state:',
          get().state,
          'transcribedText:',
          get().transcribedText,
        )

        // æ’å…¥æ–‡æœ¬ï¼ˆåç«¯ä¼šè‡ªåŠ¨æ¿€æ´»åŸåº”ç”¨ï¼‰
        console.log('[RecordingStore] Inserting text...')
        await get().insertText()
        console.log('[RecordingStore] âœ… Text inserted successfully')

        // ğŸ”Š æ’­æ”¾å®ŒæˆéŸ³æ•ˆï¼ˆåœ¨éšè—çª—å£ä¹‹å‰æ’­æ”¾ï¼‰
        audioFeedback.playOk().catch((err) => {
          console.warn('[RecordingStore] Failed to play ok sound:', err)
        })

        // æ¸…é™¤æ‰€æœ‰æç¤ºï¼ˆåŒ…æ‹¬é•¿éŸ³é¢‘æç¤ºï¼‰
        get().clearToast()

        // æ’å…¥å®Œæˆåéšè—çª—å£
        const window = getCurrentWindow()
        await window.hide()

        // é‡ç½®çŠ¶æ€
        set({
          state: 'idle',
          transcribedText: '',
        })
      } else {
        // é¢„è§ˆæ¨¡å¼ï¼šè®¾ç½®ä¸º idle çŠ¶æ€ï¼Œä¿æŒçª—å£æ˜¾ç¤ºï¼Œç­‰å¾…ç”¨æˆ·æ“ä½œ
        set({
          state: 'idle',
          transcription: transcriptionText,
          transcribedText: transcriptionText,
          duration: 0,
          audioLevel: 0,
        })
      }
    } catch (error) {
      console.error('[RecordingStore] Transcription error:', error)

      // æ ¹æ®æ“ä½œæ¨¡å¼å¤„ç†é”™è¯¯ï¼ˆç›´æ¥ä» settingsStore è¯»å–ï¼Œç¡®ä¿åŒæ­¥ï¼‰
      const errorSettings = useSettingsStore.getState().settings
      const errorMode = errorSettings.operationMode || 'preview'
      const errorMessage = `è½¬å½•å¤±è´¥: ${String(error)}`

      if (errorMode === 'direct') {
        // ç›´æ¥æ’å…¥æ¨¡å¼ï¼šæ˜¾ç¤ºé”™è¯¯æç¤ºï¼ˆä¸€èˆ¬é”™è¯¯ï¼Œ5ç§’è‡ªåŠ¨æ¶ˆå¤±ï¼‰ï¼Œç„¶åéšè—çª—å£
        console.log('[RecordingStore] Direct mode: showing error toast then hiding window')
        get().showToast('error', errorMessage, false, 5000)

        // å»¶è¿Ÿéšè—çª—å£ï¼Œè®©ç”¨æˆ·çœ‹åˆ°é”™è¯¯æç¤º
        setTimeout(async () => {
          const window = getCurrentWindow()
          await window.hide()
        }, 5000)

        set({ state: 'idle', error: errorMessage, transcribedText: '' })
      } else {
        // é¢„è§ˆæ¨¡å¼ï¼šæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯ï¼ˆä¿æŒç°æœ‰è¡Œä¸ºï¼‰
        set({ state: 'error', error: errorMessage })
      }
    }
  },

  cancelRecording: () => {
    // Clear timer
    if (window.__recordingTimer) {
      clearInterval(window.__recordingTimer)
      delete window.__recordingTimer
    }

    // åœæ­¢å‰ç«¯éŸ³é¢‘é‡‡é›†
    const audioCapture = get().audioCapture
    if (audioCapture) {
      audioCapture.cancel()
    }

    set({
      state: 'idle',
      duration: 0,
      transcription: null,
      transcribedText: '',
      error: null,
      audioLevel: 0,
      audioCapture: null,
    })
  },

  setAudioLevel: (level: number) => {
    set({ audioLevel: level })
  },

  resetState: () => {
    set({
      state: 'idle',
      duration: 0,
      transcription: null,
      transcribedText: '',
      error: null,
      audioLevel: 0,
    })
  },

  setOperationMode: (mode: OperationMode) => {
    set({ operationMode: mode })
  },

  // New text actions
  setTranscribedText: (text: string) => {
    set({ transcribedText: text })
  },

  clearText: () => {
    set({ transcribedText: '', state: 'idle' })
  },

  copyText: async () => {
    const text = get().transcribedText
    if (text) {
      try {
        await writeText(text)
        console.log('[RecordingStore] Text copied to clipboard')
      } catch (error) {
        console.error('[RecordingStore] Failed to copy text:', error)
        set({ error: 'Failed to copy text to clipboard' })
      }
    }
  },

  insertText: async () => {
    // ä½¿ç”¨ transcription å­—æ®µ(å®é™…çš„è½¬å½•æ–‡æœ¬),è€Œä¸æ˜¯ transcribedText(UI æ˜¾ç¤ºæ–‡æœ¬)
    const text = get().transcription || get().transcribedText
    if (text) {
      try {
        console.log('[RecordingStore] Checking accessibility permission...')

        // æ£€æŸ¥è¾…åŠ©åŠŸèƒ½æƒé™
        const hasPermission = await invoke<boolean>('check_accessibility_permission_cmd')
        console.log('[RecordingStore] Accessibility permission:', hasPermission)

        if (!hasPermission) {
          console.log('[RecordingStore] Requesting accessibility permission...')
          await invoke('request_accessibility_permission_cmd')

          // æ˜¾ç¤ºæƒé™é”™è¯¯æç¤ºï¼ˆä¸¥é‡é”™è¯¯ï¼Œéœ€è¦æ‰‹åŠ¨å…³é—­ï¼‰
          get().showToast('error', 'éœ€è¦è¾…åŠ©åŠŸèƒ½æƒé™æ‰èƒ½æ’å…¥æ–‡æœ¬ã€‚è¯·åœ¨ç³»ç»Ÿè®¾ç½®ä¸­æˆæƒã€‚', true, 0)
          set({ error: 'éœ€è¦è¾…åŠ©åŠŸèƒ½æƒé™æ‰èƒ½æ’å…¥æ–‡æœ¬ã€‚è¯·åœ¨ç³»ç»Ÿè®¾ç½®ä¸­æˆæƒã€‚' })
          return
        }

        // æ’å…¥æ–‡æœ¬
        console.log('[RecordingStore] Inserting text:', text)
        await invoke('insert_text_at_cursor_cmd', { text })
        console.log('[RecordingStore] Text inserted successfully')
      } catch (error) {
        console.error('[RecordingStore] Failed to insert text:', error)
        const errorMessage = `æ’å…¥æ–‡æœ¬å¤±è´¥: ${String(error)}`

        // æ˜¾ç¤ºæ’å…¥å¤±è´¥é”™è¯¯ï¼ˆä¸€èˆ¬é”™è¯¯ï¼Œ5ç§’è‡ªåŠ¨æ¶ˆå¤±ï¼‰
        get().showToast('error', errorMessage, false, 5000)
        set({ error: errorMessage })
      }
    }
  },

  // Toast ç®¡ç†æ–¹æ³•
  showToast: (type: InlineToastType, message: string, dismissible = false, duration = 0) => {
    set({
      toast: {
        type,
        message,
        dismissible,
        duration,
      },
    })
  },

  clearToast: () => {
    set({ toast: null })
  },
}))
