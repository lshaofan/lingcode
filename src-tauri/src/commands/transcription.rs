/// è½¬å½•å‘½ä»¤æ¨¡å—
/// æä¾›éŸ³é¢‘è½¬å½•ç›¸å…³çš„ Tauri commands

use parking_lot::Mutex;
use std::path::PathBuf;
use std::sync::Arc;
use tauri::{AppHandle, Emitter, Manager, State};

use crate::whisper::{convert_i16_to_f32, WhisperEngine};

/// Whisper å¼•æ“çŠ¶æ€
pub struct WhisperState {
    engine: Arc<Mutex<Option<WhisperEngine>>>,
    current_model: Arc<Mutex<Option<String>>>,
}

impl WhisperState {
    pub fn new() -> Self {
        Self {
            engine: Arc::new(Mutex::new(None)),
            current_model: Arc::new(Mutex::new(None)),
        }
    }
}

/// åˆå§‹åŒ– Whisper å¼•æ“
#[tauri::command]
pub async fn initialize_whisper(
    app: AppHandle,
    model_name: String,
    state: State<'_, WhisperState>,
) -> Result<(), String> {
    use tracing::info;

    info!("ğŸ¯ [Whisper] Initializing Whisper engine with model: {}", model_name);

    // è·å–æ¨¡å‹è·¯å¾„
    let models_dir = get_models_dir(&app)?;
    let model_path = models_dir.join(format!("ggml-{}.bin", model_name));

    info!("ğŸ¯ [Whisper] Looking for model at: {:?}", model_path);

    if !model_path.exists() {
        info!("ğŸ¯ [Whisper] Model not found, checking models directory: {:?}", models_dir);

        // åˆ—å‡º models ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
        if models_dir.exists() {
            if let Ok(entries) = std::fs::read_dir(&models_dir) {
                info!("ğŸ¯ [Whisper] Files in models directory:");
                for entry in entries {
                    if let Ok(entry) = entry {
                        info!("  - {:?}", entry.file_name());
                    }
                }
            }
        } else {
            info!("ğŸ¯ [Whisper] Models directory does not exist!");
        }

        return Err(format!("Model '{}' not found at {}. Please download it first.", model_name, model_path.display()));
    }

    // åˆ›å»º Whisper å¼•æ“
    let engine = WhisperEngine::new(&model_path)
        .map_err(|e| format!("Failed to initialize Whisper engine: {}", e))?;

    // ä¿å­˜åˆ°çŠ¶æ€
    *state.engine.lock() = Some(engine);
    *state.current_model.lock() = Some(model_name);

    Ok(())
}

/// è½¬å½•éŸ³é¢‘
#[tauri::command]
pub async fn transcribe_audio(
    audio_data: Vec<i16>,
    language: Option<String>,
    state: State<'_, WhisperState>,
) -> Result<String, String> {
    use tracing::info;

    info!("ğŸ¯ [Transcription] transcribe_audio called, language: {:?}", language);

    // å¦‚æœæ˜¯ä¸­æ–‡ç›¸å…³çš„è¯­è¨€ä»£ç ï¼Œç»Ÿä¸€ä½¿ç”¨ "zh"
    let normalized_language = language.map(|lang| {
        if lang.starts_with("zh") || lang == "chinese" || lang == "Chinese" {
            info!("ğŸ¯ [Transcription] Normalizing language '{}' to 'zh'", lang);
            "zh".to_string()
        } else {
            lang
        }
    });

    // æ£€æŸ¥å¼•æ“æ˜¯å¦å·²åˆå§‹åŒ–
    let engine = state.engine.lock();
    let engine = engine.as_ref().ok_or_else(|| {
        "Whisper engine not initialized. Please call initialize_whisper first.".to_string()
    })?;

    // è½¬æ¢éŸ³é¢‘æ ¼å¼ (i16 -> f32)
    let audio_f32 = convert_i16_to_f32(&audio_data);

    // æ‰§è¡Œè½¬å½•
    let text = engine
        .transcribe(&audio_f32, normalized_language.as_deref())
        .map_err(|e| format!("Transcription failed: {}", e))?;

    Ok(text)
}

/// è½¬å½•æœ€åä¸€æ¬¡å½•éŸ³
/// ä»å…¨å±€ LAST_RECORDING ä¸­è·å–å½•éŸ³æ•°æ®å¹¶è½¬å½•
#[tauri::command]
pub async fn transcribe_last_recording(
    language: Option<String>,
    state: State<'_, WhisperState>,
) -> Result<String, String> {
    use tracing::info;

    info!("ğŸ¯ [Transcription] transcribe_last_recording called, language: {:?}", language);

    // å¦‚æœæ˜¯ä¸­æ–‡ç›¸å…³çš„è¯­è¨€ä»£ç ï¼Œç»Ÿä¸€ä½¿ç”¨ "zh"
    let normalized_language = language.map(|lang| {
        if lang.starts_with("zh") || lang == "chinese" || lang == "Chinese" {
            info!("ğŸ¯ [Transcription] Normalizing language '{}' to 'zh'", lang);
            "zh".to_string()
        } else {
            lang
        }
    });

    info!("ğŸ¯ [Transcription] Using normalized language: {:?}", normalized_language);

    // è·å–æœ€åä¸€æ¬¡å½•éŸ³ - ä½¿ç”¨å…¨å±€é™æ€å˜é‡
    use super::audio::{LAST_RECORDING};
    let last_recording = LAST_RECORDING.lock();
    let audio_data = last_recording
        .as_ref()
        .ok_or("No recording available. Please record audio first.".to_string())?;

    info!("ğŸ¯ [Transcription] Audio data available: {} samples at 48kHz", audio_data.len());

    // æ£€æŸ¥å¼•æ“æ˜¯å¦å·²åˆå§‹åŒ–
    let engine = state.engine.lock();
    let engine = engine.as_ref().ok_or_else(|| {
        info!("ğŸ¯ [Transcription] Whisper engine not initialized!");
        "Whisper engine not initialized. Please download a model first.".to_string()
    })?;

    // è½¬æ¢éŸ³é¢‘æ ¼å¼ (i16 -> f32)
    let mut audio_f32 = convert_i16_to_f32(audio_data);

    // é‡é‡‡æ ·ä» 48kHz åˆ° 16kHzï¼ˆWhisper éœ€è¦ 16kHzï¼‰
    use crate::whisper::resample_48khz_to_16khz;
    audio_f32 = resample_48khz_to_16khz(&audio_f32);
    info!("ğŸ¯ [Transcription] Resampled to 16kHz: {} samples", audio_f32.len());

    // æ‰§è¡Œè½¬å½•
    let text = engine
        .transcribe(&audio_f32, normalized_language.as_deref())
        .map_err(|e| format!("Transcription failed: {}", e))?;

    // ğŸ”‘ éªŒè¯è½¬å½•ç»“æœæ˜¯å¦æœ‰æ•ˆ
    // æ£€æµ‹ Whisper çš„"å¹»è§‰"è¾“å‡ºï¼ˆé™éŸ³æ—¶ç»å¸¸è¾“å‡ºçš„æ— æ„ä¹‰å†…å®¹ï¼‰
    if is_invalid_transcription(&text, &audio_f32) {
        info!("ğŸ¯ [Transcription] Invalid transcription detected (hallucination or silence): '{}'", text);
        return Err("è½¬å½•ç»“æœæ— æ•ˆï¼šå¯èƒ½æ˜¯é™éŸ³æˆ–å™ªéŸ³".to_string());
    }

    info!("ğŸ¯ [Transcription] Valid transcription: '{}'", text);
    Ok(text)
}

/// è½¬å½•éŸ³é¢‘ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
#[tauri::command]
pub async fn transcribe_audio_with_timestamps(
    audio_data: Vec<i16>,
    language: Option<String>,
    state: State<'_, WhisperState>,
) -> Result<Vec<TranscriptionSegmentDTO>, String> {
    use tracing::info;

    info!("ğŸ¯ [Transcription] transcribe_audio_with_timestamps called, language: {:?}", language);

    // å¦‚æœæ˜¯ä¸­æ–‡ç›¸å…³çš„è¯­è¨€ä»£ç ï¼Œç»Ÿä¸€ä½¿ç”¨ "zh"
    let normalized_language = language.map(|lang| {
        if lang.starts_with("zh") || lang == "chinese" || lang == "Chinese" {
            info!("ğŸ¯ [Transcription] Normalizing language '{}' to 'zh'", lang);
            "zh".to_string()
        } else {
            lang
        }
    });

    // æ£€æŸ¥å¼•æ“æ˜¯å¦å·²åˆå§‹åŒ–
    let engine = state.engine.lock();
    let engine = engine.as_ref().ok_or_else(|| {
        "Whisper engine not initialized. Please call initialize_whisper first.".to_string()
    })?;

    // è½¬æ¢éŸ³é¢‘æ ¼å¼ (i16 -> f32)
    let audio_f32 = convert_i16_to_f32(&audio_data);

    // æ‰§è¡Œè½¬å½•
    let segments = engine
        .transcribe_with_timestamps(&audio_f32, normalized_language.as_deref())
        .map_err(|e| format!("Transcription failed: {}", e))?;

    // è½¬æ¢ä¸º DTO
    let segments_dto: Vec<TranscriptionSegmentDTO> = segments
        .into_iter()
        .map(|s| TranscriptionSegmentDTO {
            text: s.text,
            start_ms: s.start_ms,
            end_ms: s.end_ms,
        })
        .collect();

    Ok(segments_dto)
}

/// è·å–å½“å‰ä½¿ç”¨çš„æ¨¡å‹åç§°
#[tauri::command]
pub fn get_current_model(state: State<'_, WhisperState>) -> Result<Option<String>, String> {
    let model = state.current_model.lock();
    Ok(model.clone())
}

/// è½¬å½•æ®µè½ DTO
#[derive(serde::Serialize, serde::Deserialize, Clone)]
pub struct TranscriptionSegmentDTO {
    pub text: String,
    pub start_ms: u64,
    pub end_ms: u64,
}

// è¾…åŠ©å‡½æ•°

fn get_models_dir(app: &AppHandle) -> Result<PathBuf, String> {
    let app_data_dir = app
        .path()
        .app_data_dir()
        .map_err(|e| format!("Failed to get app data dir: {}", e))?;

    Ok(app_data_dir.join("models"))
}

/// æ£€æµ‹è½¬å½•ç»“æœæ˜¯å¦æ— æ•ˆï¼ˆWhisper å¹»è§‰æˆ–é™éŸ³ï¼‰
///
/// å¸¸è§çš„æ— æ•ˆæƒ…å†µï¼š
/// 1. éŸ³é¢‘å¤ªçŸ­ï¼ˆå°‘äº 0.3 ç§’ï¼‰
/// 2. åŒ…å« Whisper å¸¸è§çš„å¹»è§‰è¯æ±‡ï¼ˆ"å­—å¹•"ã€"J Chong" ç­‰ï¼‰
/// 3. æ–‡æœ¬å¤ªçŸ­æˆ–åªæœ‰æ ‡ç‚¹ç¬¦å·
fn is_invalid_transcription(text: &str, audio_f32: &[f32]) -> bool {
    // 1. æ£€æŸ¥éŸ³é¢‘é•¿åº¦ï¼ˆ16kHz é‡‡æ ·ç‡ï¼‰
    let duration_seconds = audio_f32.len() as f32 / 16000.0;
    if duration_seconds < 0.3 {
        return true;
    }

    // 2. å»é™¤ç©ºç™½å­—ç¬¦
    let trimmed = text.trim();

    // 3. æ£€æŸ¥æ˜¯å¦ä¸ºç©ºæˆ–å¤ªçŸ­
    if trimmed.is_empty() || trimmed.len() < 2 {
        return true;
    }

    // 4. æ£€æŸ¥æ˜¯å¦åªåŒ…å«æ ‡ç‚¹ç¬¦å·å’Œæ‹¬å·
    let has_meaningful_char = trimmed.chars().any(|c| {
        !c.is_whitespace() && !".,!?;:()[]{}\"'ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šï¼ˆï¼‰ã€ã€‘ã€Œã€ã€ã€".contains(c)
    });

    if !has_meaningful_char {
        return true;
    }

    // 5. æ£€æŸ¥å¸¸è§çš„ Whisper å¹»è§‰æ¨¡å¼ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    let lower_text = text.to_lowercase();
    let hallucination_patterns = [
        "å­—å¹•",
        "subtitle",
        "j chong",
        "jchong",
        "thanks for watching",
        "è¯·ä¸åç‚¹èµ",
        "è®¢é˜…",
        "subscribe",
        "ç¿»è¯‘",
        "translation",
        "(music)",
        "[music]",
        "(laughs)",
        "[laughs]",
        "(applause)",
        "[applause]",
    ];

    for pattern in &hallucination_patterns {
        if lower_text.contains(pattern) {
            return true;
        }
    }

    // 6. æ£€æŸ¥æ˜¯å¦åªæ˜¯å•ä¸ªæ‹¬å·å†…å®¹ï¼ˆå¦‚ "(å­—å¹•:xxx)"ï¼‰
    if trimmed.starts_with('(') && trimmed.ends_with(')') && !trimmed[1..trimmed.len()-1].contains('(') {
        return true;
    }

    // æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼Œè®¤ä¸ºæ˜¯æœ‰æ•ˆçš„è½¬å½•
    false
}
