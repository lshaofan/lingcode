/**
 * å‰ç«¯éŸ³é¢‘é‡‡é›†æ¨¡å—
 * ä½¿ç”¨ getUserMedia API è¿›è¡ŒéŸ³é¢‘é‡‡é›†ï¼Œç¡®ä¿ macOS éº¦å…‹é£å›¾æ ‡æ­£ç¡®æ˜¾ç¤º
 *
 * ç‰¹æ€§ï¼š
 * - ä½¿ç”¨ Web Audio API + getUserMedia (ç¡®ä¿ç³»ç»Ÿéº¦å…‹é£æŒ‡ç¤ºå™¨æ˜¾ç¤º)
 * - æ”¯æŒå®æ—¶éŸ³é¢‘æµé‡‡é›†
 * - æ”¯æŒéŸ³é¢‘æ ¼å¼è½¬æ¢ (Float32 â†’ PCM16)
 * - ä¸ºæœªæ¥çš„å®æ—¶è½¬å½•åŠŸèƒ½é¢„ç•™æ‰©å±•ç‚¹
 */

export interface AudioCaptureConfig {
  sampleRate?: number // é‡‡æ ·ç‡ï¼Œé»˜è®¤ 16000 Hz
  channelCount?: number // å£°é“æ•°ï¼Œé»˜è®¤ 1 (å•å£°é“)
  echoCancellation?: boolean // å›å£°æ¶ˆé™¤ï¼Œé»˜è®¤ true
  noiseSuppression?: boolean // é™å™ªï¼Œé»˜è®¤ true
  autoGainControl?: boolean // è‡ªåŠ¨å¢ç›Šæ§åˆ¶ï¼Œé»˜è®¤ true
}

export interface AudioCaptureDevice {
  deviceId: string
  label: string
  groupId: string
}

// ğŸ”‘ å…¨å±€å®ä¾‹è·Ÿè¸ªï¼Œç”¨äºé˜²æ­¢æ³„æ¼
const activeInstances = new Set<AudioCapture>()

// ğŸ”‘ å…¨å±€æ¸…ç†ï¼šé¡µé¢å¸è½½æ—¶å¼ºåˆ¶æ¸…ç†æ‰€æœ‰å®ä¾‹
if (typeof window !== 'undefined') {
  window.addEventListener('beforeunload', () => {
    console.log('[AudioCapture] ğŸš¨ Page unloading, force cleaning all instances')
    const instances = Array.from(activeInstances)
    instances.forEach((instance) => {
      instance.cancel()
    })
  })
}

export class AudioCapture {
  private stream: MediaStream | null = null
  private audioContext: AudioContext | null = null
  private mediaRecorder: MediaRecorder | null = null
  private audioChunks: Blob[] = []
  private config: Required<AudioCaptureConfig>
  private _isDestroyed = false // æ ‡è®°å®ä¾‹æ˜¯å¦å·²é”€æ¯
  private _isPrewarmed = false // æ ‡è®°æ˜¯å¦å·²é¢„çƒ­(getUserMediaå®Œæˆä½†MediaRecorderæœªstart)

  constructor(config: AudioCaptureConfig = {}) {
    this.config = {
      sampleRate: config.sampleRate ?? 16000,
      channelCount: config.channelCount ?? 1,
      echoCancellation: config.echoCancellation ?? true,
      noiseSuppression: config.noiseSuppression ?? true,
      autoGainControl: config.autoGainControl ?? true,
    }

    // ğŸ”‘ æ³¨å†Œå®ä¾‹
    activeInstances.add(this)
    console.log('[AudioCapture] ğŸ“ Instance created, total active instances:', activeInstances.size)
  }

  /**
   * è·å–éŸ³é¢‘æµ
   * ç”¨äºAudioCacheManagerç›‘å¬éŸ³é¢‘è½¨é“çŠ¶æ€
   */
  get stream_(): MediaStream | null {
    return this.stream
  }

  /**
   * æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦æ”¯æŒ getUserMedia
   */
  static isSupported(): boolean {
    const supported = !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia)
    console.log('[AudioCapture] ğŸ” Checking getUserMedia support:')
    console.log('  - navigator.mediaDevices:', !!navigator.mediaDevices)
    console.log('  - getUserMedia method:', !!navigator.mediaDevices?.getUserMedia)
    console.log('  - Current URL:', window.location.href)
    console.log('  - Is secure context:', window.isSecureContext)
    return supported
  }

  /**
   * æ¸…ç†æ‰€æœ‰æ´»åŠ¨çš„ AudioCapture å®ä¾‹
   * ç”¨äºé˜²æ­¢çƒ­é‡è½½æ—¶çš„å®ä¾‹æ³„æ¼
   */
  static cleanupAllInstances(): void {
    console.log('[AudioCapture] ğŸ§¹ Cleaning up all active instances, count:', activeInstances.size)
    const instances = Array.from(activeInstances)
    instances.forEach((instance) => {
      instance.cancel()
    })
    console.log('[AudioCapture] âœ… All instances cleaned up')
  }

  /**
   * é¢„çƒ­ï¼šæå‰åˆå§‹åŒ– getUserMedia å’Œ MediaRecorderï¼Œä½†ä¸å¼€å§‹å½•éŸ³
   * è¿™æ ·å¯ä»¥å‡å°‘ç”¨æˆ·æŒ‰ä¸‹å¿«æ·é”®åˆ°çœŸæ­£å¼€å§‹å½•éŸ³ä¹‹é—´çš„å»¶è¿Ÿ
   * @param deviceId å¯é€‰çš„è®¾å¤‡ ID
   */
  async prewarm(deviceId?: string): Promise<void> {
    console.log('[AudioCapture] ğŸ”¥ Prewarming - initializing getUserMedia and MediaRecorder...')

    // é˜²æ­¢åœ¨å·²é”€æ¯çš„å®ä¾‹ä¸Šè°ƒç”¨
    if (this._isDestroyed) {
      console.error('[AudioCapture] âŒ Cannot prewarm on destroyed instance')
      throw new Error('Cannot prewarm on destroyed AudioCapture instance')
    }

    if (this.stream) {
      console.warn('[AudioCapture] Already initialized, skipping prewarm')
      return
    }

    try {
      console.log('[AudioCapture] Step 1: Requesting getUserMedia...')

      // æ„å»ºéŸ³é¢‘çº¦æŸ
      const constraints: MediaStreamConstraints = {
        audio: {
          deviceId: deviceId ? { exact: deviceId } : undefined,
          sampleRate: { ideal: this.config.sampleRate },
          channelCount: { ideal: this.config.channelCount },
          echoCancellation: this.config.echoCancellation,
          noiseSuppression: this.config.noiseSuppression,
          autoGainControl: this.config.autoGainControl,
        },
      }

      // ğŸ¯ å…³é”®ï¼šè·å–éº¦å…‹é£æƒé™å¹¶åˆ›å»ºéŸ³é¢‘æµ
      // è¿™ä¼šè§¦å‘æµè§ˆå™¨çš„éº¦å…‹é£æƒé™è¯·æ±‚(å¦‚æœéœ€è¦)
      // å¹¶æ˜¾ç¤ºç³»ç»Ÿéº¦å…‹é£æŒ‡ç¤ºå™¨
      this.stream = await navigator.mediaDevices.getUserMedia(constraints)
      console.log('[AudioCapture] âœ… getUserMedia completed, stream created')

      // åˆ›å»º AudioContext (ç”¨äºåç»­çš„éŸ³é¢‘è½¬æ¢)
      this.audioContext = new AudioContext({
        sampleRate: this.config.sampleRate,
      })
      console.log('[AudioCapture] âœ… AudioContext created')

      // ç¡®å®šæ”¯æŒçš„ MIME ç±»å‹
      const mimeType = this.getSupportedMimeType()
      console.log('[AudioCapture] Using MIME type:', mimeType)

      // åˆ›å»º MediaRecorder (ä½†ä¸å¯åŠ¨)
      this.mediaRecorder = new MediaRecorder(this.stream, {
        mimeType,
        audioBitsPerSecond: 128000,
      })
      console.log('[AudioCapture] âœ… MediaRecorder created (ready to start)')

      // è®¾ç½®äº‹ä»¶å¤„ç†å™¨
      this.audioChunks = []
      this.mediaRecorder.ondataavailable = (event) => {
        if (this._isDestroyed) {
          console.log('[AudioCapture] âš ï¸  Ignoring chunk from destroyed instance')
          return
        }
        if (event.data.size > 0) {
          this.audioChunks.push(event.data)
          console.log('[AudioCapture] Audio chunk received:', event.data.size, 'bytes')
        }
      }

      // æ ‡è®°ä¸ºå·²é¢„çƒ­
      this._isPrewarmed = true
      console.log('[AudioCapture] ğŸ”¥âœ… Prewarm completed! Ready to start recording instantly.')
    } catch (error) {
      console.error('[AudioCapture] Prewarm failed:', error)
      this.cleanup()
      throw error
    }
  }

  /**
   * è·å–å¯ç”¨çš„éŸ³é¢‘è¾“å…¥è®¾å¤‡åˆ—è¡¨
   */
  static async getDevices(): Promise<AudioCaptureDevice[]> {
    if (!AudioCapture.isSupported()) {
      throw new Error('getUserMedia is not supported in this browser')
    }

    const devices = await navigator.mediaDevices.enumerateDevices()
    return devices
      .filter((device) => device.kind === 'audioinput')
      .map((device) => ({
        deviceId: device.deviceId,
        label: device.label || `Microphone ${device.deviceId.slice(0, 8)}`,
        groupId: device.groupId,
      }))
  }

  /**
   * å¼€å§‹éŸ³é¢‘é‡‡é›†
   * @param deviceId å¯é€‰çš„è®¾å¤‡ IDï¼Œä¸æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤è®¾å¤‡
   */
  async start(deviceId?: string): Promise<void> {
    // é˜²æ­¢åœ¨å·²é”€æ¯çš„å®ä¾‹ä¸Šè°ƒç”¨
    if (this._isDestroyed) {
      console.error('[AudioCapture] âŒ Cannot start on destroyed instance')
      throw new Error('Cannot start on destroyed AudioCapture instance')
    }

    console.log('[AudioCapture] ğŸ¤ Starting audio capture...')

    // ğŸ”¥ æ£€æŸ¥æ˜¯å¦å·²ç»é¢„çƒ­
    if (this._isPrewarmed && this.mediaRecorder) {
      console.log('[AudioCapture] âš¡ Using prewarmed MediaRecorder - INSTANT START!')
      // MediaRecorder å·²ç»å°±ç»ª,ç›´æ¥å¼€å§‹å½•éŸ³
      this.mediaRecorder.start()
      console.log('[AudioCapture] âœ… MediaRecorder started instantly (prewarmed)')
      return
    }

    // æœªé¢„çƒ­,èµ°å®Œæ•´çš„åˆå§‹åŒ–æµç¨‹
    if (this.stream) {
      console.warn('[AudioCapture] Already recording')
      return
    }

    console.log('[AudioCapture] ğŸ¤ Starting audio capture with config:', this.config)

    try {
      // æ„å»ºçº¦æŸæ¡ä»¶
      const constraints: MediaStreamConstraints = {
        audio: {
          sampleRate: this.config.sampleRate,
          channelCount: this.config.channelCount,
          echoCancellation: this.config.echoCancellation,
          noiseSuppression: this.config.noiseSuppression,
          autoGainControl: this.config.autoGainControl,
          ...(deviceId && { deviceId: { exact: deviceId } }),
        },
        video: false,
      }

      // è¯·æ±‚éº¦å…‹é£æƒé™å¹¶è·å–éŸ³é¢‘æµ
      // ğŸ¯ å…³é”®ï¼šè¿™ä¸€æ­¥ä¼šè§¦å‘ macOS çš„éº¦å…‹é£å›¾æ ‡æ˜¾ç¤º
      console.log('[AudioCapture] ğŸ¤ Requesting getUserMedia with constraints:', constraints)
      this.stream = await navigator.mediaDevices.getUserMedia(constraints)
      console.log('[AudioCapture] âœ… Got media stream, microphone indicator should be active')

      // ğŸ” è¯Šæ–­ï¼šæ£€æŸ¥éŸ³é¢‘è½¨é“çŠ¶æ€
      const audioTracks = this.stream.getAudioTracks()
      console.log('[AudioCapture] ğŸ“Š Audio tracks:', audioTracks.length)
      audioTracks.forEach((track, index) => {
        console.log(`[AudioCapture] Track ${index}:`, {
          label: track.label,
          enabled: track.enabled,
          muted: track.muted,
          readyState: track.readyState,
          id: track.id,
        })
      })

      // åˆ›å»º AudioContextï¼ˆç”¨äºéŸ³é¢‘å¤„ç†ï¼‰
      this.audioContext = new AudioContext({
        sampleRate: this.config.sampleRate,
      })

      // åˆ›å»º MediaRecorder ç”¨äºå½•åˆ¶
      // ä½¿ç”¨ webm æ ¼å¼ï¼Œå› ä¸ºæµè§ˆå™¨åŸç”Ÿæ”¯æŒ
      const mimeType = this.getSupportedMimeType()
      this.mediaRecorder = new MediaRecorder(this.stream, {
        mimeType,
        audioBitsPerSecond: 128000, // 128 kbps
      })
      console.log('[AudioCapture] ğŸ“¹ MediaRecorder created with mimeType:', mimeType)

      // ç›‘å¬æ•°æ®äº‹ä»¶
      this.audioChunks = []
      this.mediaRecorder.ondataavailable = (event) => {
        // ğŸ”‘ å…³é”®ä¿®å¤ï¼šå¦‚æœå®ä¾‹å·²é”€æ¯ï¼Œç›´æ¥å¿½ç•¥äº‹ä»¶
        if (this._isDestroyed) {
          console.log('[AudioCapture] âš ï¸  Ignoring chunk from destroyed instance')
          return
        }

        if (event.data.size > 0) {
          this.audioChunks.push(event.data)
          console.log('[AudioCapture] Audio chunk received:', event.data.size, 'bytes')
        }
      }

      // å¼€å§‹å½•åˆ¶
      // ğŸ”‘ å…³é”®ä¿®å¤ï¼šä¸è®¾ç½® timesliceï¼Œé¿å…éŸ³é¢‘ä¸¢å¤±
      // ä¸ä¼ å‚æ•°æ—¶ï¼ŒMediaRecorder ä¼šåœ¨ stop() æ—¶ä¸€æ¬¡æ€§è¿”å›æ‰€æœ‰éŸ³é¢‘æ•°æ®
      // è¿™ç¡®ä¿äº†éŸ³é¢‘çš„å®Œæ•´æ€§ï¼Œä¸ä¼šä¸¢å¤±å¼€å¤´æˆ–ç»“å°¾
      this.mediaRecorder.start()
      console.log(
        '[AudioCapture] âœ… MediaRecorder started (no timeslice - will collect all data on stop)',
      )
    } catch (error) {
      console.error('[AudioCapture] Failed to start audio capture:', error)
      this.cleanup()
      throw error
    }
  }

  /**
   * åœæ­¢éŸ³é¢‘é‡‡é›†å¹¶è¿”å›å½•éŸ³æ•°æ®
   * @returns è¿”å›éŸ³é¢‘ Blob æ•°æ®
   */
  async stop(): Promise<Blob> {
    return new Promise((resolve, reject) => {
      if (!this.mediaRecorder || !this.stream) {
        reject(new Error('Not recording'))
        return
      }

      console.log('[AudioCapture] ğŸ›‘ Stopping audio capture...')

      // ğŸ”‘ å…³é”®ä¿®å¤ï¼šå…ˆä¿å­˜ chunks çš„å¼•ç”¨
      const chunks = this.audioChunks

      // è®¾ç½®åœæ­¢äº‹ä»¶ç›‘å¬å™¨
      this.mediaRecorder.onstop = () => {
        console.log('[AudioCapture] MediaRecorder stopped, chunks:', chunks.length)

        // åˆå¹¶æ‰€æœ‰éŸ³é¢‘å—
        const mimeType = this.getSupportedMimeType()
        const audioBlob = new Blob(chunks, { type: mimeType })
        console.log('[AudioCapture] âœ… Audio blob created:', audioBlob.size, 'bytes')

        // æ¸…ç†èµ„æº
        this.cleanup()

        resolve(audioBlob)
      }

      // ğŸ”‘ é‡è¦ï¼šä¸è¦åœ¨ stop() ä¹‹å‰æ¸…é™¤ ondataavailableï¼
      // å½“ä¸ä½¿ç”¨ timeslice æ—¶ï¼Œstop() ä¼šè§¦å‘æœ€åä¸€æ¬¡ ondataavailable äº‹ä»¶
      // è¿™ä¸ªäº‹ä»¶åŒ…å«äº†æ‰€æœ‰å½•åˆ¶çš„éŸ³é¢‘æ•°æ®
      // æˆ‘ä»¬éœ€è¦ç­‰è¿™ä¸ªäº‹ä»¶å®Œæˆåï¼Œåœ¨ cleanup() ä¸­æ¸…é™¤å¤„ç†å™¨

      // åœæ­¢å½•åˆ¶
      console.log('[AudioCapture] ğŸ“¤ Calling stop() - will trigger final ondataavailable')
      this.mediaRecorder.stop()
    })
  }

  /**
   * å–æ¶ˆå½•åˆ¶
   */
  cancel(): void {
    console.log('[AudioCapture] Cancelling audio capture')
    this.cleanup()
  }

  /**
   * è·å–å½“å‰æ˜¯å¦æ­£åœ¨å½•åˆ¶
   */
  isRecording(): boolean {
    return this.mediaRecorder?.state === 'recording'
  }

  /**
   * æ¸…ç†èµ„æº
   */
  private cleanup(): void {
    // é˜²æ­¢é‡å¤æ¸…ç†
    if (this._isDestroyed) {
      console.log('[AudioCapture] âš ï¸  Already destroyed, skipping cleanup')
      return
    }

    console.log('[AudioCapture] ğŸ§¹ Starting cleanup...')
    this._isDestroyed = true

    // ğŸ”‘ å…³é”®ä¿®å¤ï¼šå…ˆåœæ­¢ MediaRecorder å¹¶æ¸…é™¤äº‹ä»¶å¤„ç†å™¨
    if (this.mediaRecorder) {
      // å¦‚æœè¿˜åœ¨å½•åˆ¶çŠ¶æ€ï¼Œå…ˆåœæ­¢
      if (this.mediaRecorder.state === 'recording' || this.mediaRecorder.state === 'paused') {
        try {
          this.mediaRecorder.stop()
          console.log('[AudioCapture] ğŸ›‘ MediaRecorder stopped in cleanup')
        } catch (error) {
          console.error('[AudioCapture] Error stopping MediaRecorder:', error)
        }
      }

      // æ¸…é™¤æ‰€æœ‰äº‹ä»¶å¤„ç†å™¨ï¼ˆé˜²æ­¢ç»§ç»­è§¦å‘ï¼‰
      this.mediaRecorder.ondataavailable = null
      this.mediaRecorder.onstop = null
      this.mediaRecorder.onerror = null
      this.mediaRecorder = null
      console.log('[AudioCapture] ğŸ§¹ MediaRecorder event handlers cleared')
    }

    // åœæ­¢æ‰€æœ‰éŸ³é¢‘è½¨é“ï¼ˆè¿™ä¼šå…³é—­éº¦å…‹é£å¹¶éšè—æŒ‡ç¤ºå™¨ï¼‰
    if (this.stream) {
      this.stream.getTracks().forEach((track) => {
        track.stop()
        console.log('[AudioCapture] ğŸ¤ Audio track stopped')
      })
      this.stream = null
    }

    // å…³é—­ AudioContext
    if (this.audioContext) {
      void this.audioContext.close()
      this.audioContext = null
    }

    // æ¸…ç†éŸ³é¢‘å—æ•°ç»„
    this.audioChunks = []

    // ğŸ”‘ ä»å…¨å±€è·Ÿè¸ªä¸­ç§»é™¤
    activeInstances.delete(this)
    console.log(
      '[AudioCapture] âœ… Cleanup completed, remaining active instances:',
      activeInstances.size,
    )
  }

  /**
   * è·å–æ”¯æŒçš„ MIME ç±»å‹
   */
  private getSupportedMimeType(): string {
    const types = ['audio/webm;codecs=opus', 'audio/webm', 'audio/ogg;codecs=opus', 'audio/mp4']

    for (const type of types) {
      if (MediaRecorder.isTypeSupported(type)) {
        console.log('[AudioCapture] Using MIME type:', type)
        return type
      }
    }

    console.warn('[AudioCapture] No supported MIME type found, using default')
    return 'audio/webm'
  }
}

/**
 * éŸ³é¢‘æ ¼å¼è½¬æ¢å·¥å…·
 */
export class AudioConverter {
  /**
   * å°† Blob è½¬æ¢ä¸º ArrayBuffer
   */
  static async blobToArrayBuffer(blob: Blob): Promise<ArrayBuffer> {
    return blob.arrayBuffer()
  }

  /**
   * å°† Blob è½¬æ¢ä¸º Base64 å­—ç¬¦ä¸²
   */
  static async blobToBase64(blob: Blob): Promise<string> {
    return new Promise((resolve, reject) => {
      const reader = new FileReader()
      reader.onloadend = () => {
        const result = reader.result as string
        // ç§»é™¤ data URL å‰ç¼€
        const base64 = result.split(',')[1] || ''
        resolve(base64)
      }
      reader.onerror = reject
      reader.readAsDataURL(blob)
    })
  }

  /**
   * å°†éŸ³é¢‘ Blob è§£ç ä¸º PCM æ•°æ®
   * @param blob éŸ³é¢‘ Blob
   * @param targetSampleRate ç›®æ ‡é‡‡æ ·ç‡ï¼ˆé»˜è®¤ 16000ï¼‰
   * @returns PCM16 æ•°æ®çš„ Uint8Array
   */
  static async blobToPCM16(blob: Blob, targetSampleRate: number = 16000): Promise<Uint8Array> {
    // å°† Blob è½¬æ¢ä¸º ArrayBuffer
    const arrayBuffer = await blob.arrayBuffer()

    // åˆ›å»º AudioContext è§£ç éŸ³é¢‘
    const audioContext = new AudioContext({ sampleRate: targetSampleRate })
    const audioBuffer = await audioContext.decodeAudioData(arrayBuffer)

    // è·å–éŸ³é¢‘æ•°æ®ï¼ˆå•å£°é“ï¼‰
    let audioData: Float32Array
    if (audioBuffer.numberOfChannels === 1) {
      audioData = audioBuffer.getChannelData(0)
    } else {
      // å¦‚æœæ˜¯å¤šå£°é“ï¼Œæ··åˆä¸ºå•å£°é“
      const left = audioBuffer.getChannelData(0)
      const right = audioBuffer.getChannelData(1)
      audioData = new Float32Array(left.length)
      for (let i = 0; i < left.length; i++) {
        audioData[i] = ((left[i] ?? 0) + (right[i] ?? 0)) / 2
      }
    }

    // è½¬æ¢ä¸º 16-bit PCM
    const pcm16 = AudioConverter.float32ToPCM16(audioData)

    // å…³é—­ AudioContext
    await audioContext.close()

    return pcm16
  }

  /**
   * å°† Float32 éŸ³é¢‘æ•°æ®è½¬æ¢ä¸º 16-bit PCM
   */
  static float32ToPCM16(float32Array: Float32Array): Uint8Array {
    const pcm16 = new Int16Array(float32Array.length)

    for (let i = 0; i < float32Array.length; i++) {
      // é™åˆ¶åœ¨ [-1.0, 1.0] èŒƒå›´å†…
      const s = Math.max(-1, Math.min(1, float32Array[i] ?? 0))
      // è½¬æ¢ä¸º 16-bit æ•´æ•°
      pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7fff
    }

    // è¿”å›å­—èŠ‚æ•°ç»„ï¼ˆå°ç«¯åºï¼‰
    return new Uint8Array(pcm16.buffer)
  }

  /**
   * å°†éŸ³é¢‘ Blob è½¬æ¢ä¸º WAV æ ¼å¼
   * æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•è¿”å›çš„ WAV æ•°æ®å¯ä»¥ç›´æ¥å‘é€åˆ°åç«¯
   */
  static async blobToWAV(
    blob: Blob,
    sampleRate: number = 16000,
    numChannels: number = 1,
    bitDepth: number = 16,
  ): Promise<Uint8Array> {
    // å…ˆè½¬æ¢ä¸º PCM16
    const pcm16 = await AudioConverter.blobToPCM16(blob, sampleRate)

    // åˆ›å»º WAV æ–‡ä»¶å¤´
    const wavHeader = AudioConverter.createWAVHeader(
      pcm16.length,
      sampleRate,
      numChannels,
      bitDepth,
    )

    // åˆå¹¶å¤´éƒ¨å’Œæ•°æ®
    const wavData = new Uint8Array(wavHeader.length + pcm16.length)
    wavData.set(wavHeader, 0)
    wavData.set(pcm16, wavHeader.length)

    return wavData
  }

  /**
   * åˆ›å»º WAV æ–‡ä»¶å¤´
   */
  private static createWAVHeader(
    dataSize: number,
    sampleRate: number,
    numChannels: number,
    bitDepth: number,
  ): Uint8Array {
    const header = new ArrayBuffer(44)
    const view = new DataView(header)

    // RIFF chunk descriptor
    this.writeString(view, 0, 'RIFF')
    view.setUint32(4, 36 + dataSize, true) // File size - 8
    this.writeString(view, 8, 'WAVE')

    // fmt sub-chunk
    this.writeString(view, 12, 'fmt ')
    view.setUint32(16, 16, true) // Subchunk1Size (16 for PCM)
    view.setUint16(20, 1, true) // AudioFormat (1 for PCM)
    view.setUint16(22, numChannels, true)
    view.setUint32(24, sampleRate, true)
    view.setUint32(28, (sampleRate * numChannels * bitDepth) / 8, true) // ByteRate
    view.setUint16(32, (numChannels * bitDepth) / 8, true) // BlockAlign
    view.setUint16(34, bitDepth, true)

    // data sub-chunk
    this.writeString(view, 36, 'data')
    view.setUint32(40, dataSize, true)

    return new Uint8Array(header)
  }

  /**
   * å†™å…¥å­—ç¬¦ä¸²åˆ° DataView
   */
  private static writeString(view: DataView, offset: number, string: string): void {
    for (let i = 0; i < string.length; i++) {
      view.setUint8(offset + i, string.charCodeAt(i))
    }
  }
}
