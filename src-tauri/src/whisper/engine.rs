/// Whisper è½¬å½•å¼•æ“
/// å°è£… whisper-rs æä¾›å®‰å…¨çš„è½¬å½•æ¥å£

use std::error::Error;
use std::fmt;
use std::path::{Path, PathBuf};
use whisper_rs::{FullParams, SamplingStrategy, WhisperContext, WhisperContextParameters};

use super::preprocessor::{validate_audio_data, PreprocessError};

#[derive(Debug)]
pub enum WhisperError {
    ModelNotFound(PathBuf),
    FailedToLoadModel(String),
    TranscriptionFailed(String),
    PreprocessError(PreprocessError),
    AudioTooShort,
    AudioTooLong,
}

impl fmt::Display for WhisperError {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match self {
            WhisperError::ModelNotFound(path) => {
                write!(f, "Model file not found: {}", path.display())
            }
            WhisperError::FailedToLoadModel(err) => {
                write!(f, "Failed to load Whisper model: {}", err)
            }
            WhisperError::TranscriptionFailed(err) => {
                write!(f, "Transcription failed: {}", err)
            }
            WhisperError::PreprocessError(err) => {
                write!(f, "Audio preprocessing error: {}", err)
            }
            WhisperError::AudioTooShort => {
                write!(f, "Audio too short (minimum 0.1 seconds)")
            }
            WhisperError::AudioTooLong => {
                write!(f, "Audio too long (maximum 10 minutes)")
            }
        }
    }
}

impl Error for WhisperError {}

impl From<PreprocessError> for WhisperError {
    fn from(err: PreprocessError) -> Self {
        WhisperError::PreprocessError(err)
    }
}

/// Whisper è½¬å½•å¼•æ“
pub struct WhisperEngine {
    context: WhisperContext,
    model_path: PathBuf,
    n_threads: usize,
}

impl WhisperEngine {
    /// åˆ›å»ºæ–°çš„ Whisper å¼•æ“å®ä¾‹
    ///
    /// # å‚æ•°
    /// * `model_path` - æ¨¡å‹æ–‡ä»¶è·¯å¾„
    /// * `n_threads` - æ¨ç†ä½¿ç”¨çš„çº¿ç¨‹æ•°ï¼ˆé»˜è®¤ä½¿ç”¨ CPU æ ¸å¿ƒæ•°çš„ä¸€åŠï¼‰
    pub fn new<P: AsRef<Path>>(model_path: P) -> Result<Self, WhisperError> {
        let model_path = model_path.as_ref().to_path_buf();

        // æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if !model_path.exists() {
            return Err(WhisperError::ModelNotFound(model_path));
        }

        // åˆ›å»º Whisper ä¸Šä¸‹æ–‡å‚æ•°
        let params = WhisperContextParameters::default();

        // åŠ è½½æ¨¡å‹
        let context = WhisperContext::new_with_params(
            model_path.to_str().ok_or_else(|| {
                WhisperError::FailedToLoadModel("Invalid model path encoding".to_string())
            })?,
            params,
        )
        .map_err(|e| WhisperError::FailedToLoadModel(e.to_string()))?;

        // è·å– CPU æ ¸å¿ƒæ•°ï¼Œä½¿ç”¨ä¸€åŠä½œä¸ºé»˜è®¤çº¿ç¨‹æ•°
        let n_threads = num_cpus::get() / 2;
        let n_threads = n_threads.max(1).min(8); // é™åˆ¶åœ¨ 1-8 ä¹‹é—´

        Ok(Self {
            context,
            model_path,
            n_threads,
        })
    }

    /// æ£€æŸ¥å¼•æ“æ˜¯å¦å·²åˆå§‹åŒ–
    pub fn is_initialized(&self) -> bool {
        true // å¦‚æœèƒ½åˆ›å»ºæˆåŠŸå°±æ˜¯å·²åˆå§‹åŒ–
    }

    /// è·å–æ¨¡å‹è·¯å¾„
    pub fn model_path(&self) -> &Path {
        &self.model_path
    }

    /// è½¬å½•éŸ³é¢‘
    ///
    /// # å‚æ•°
    /// * `audio_data` - f32 æ ¼å¼çš„éŸ³é¢‘æ•°æ®ï¼ˆ16kHz, å•å£°é“ï¼‰
    /// * `language` - è¯­è¨€ä»£ç ï¼ˆå¦‚ "zh", "en"ï¼‰ï¼ŒNone è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹
    ///
    /// # è¿”å›
    /// è½¬å½•åçš„æ–‡æœ¬
    pub fn transcribe(
        &self,
        audio_data: &[f32],
        language: Option<&str>,
    ) -> Result<String, WhisperError> {
        use tracing::info;

        // éªŒè¯éŸ³é¢‘æ•°æ®
        validate_audio_data(audio_data)?;

        // æ£€æŸ¥éŸ³é¢‘é•¿åº¦ï¼ˆ16kHz é‡‡æ ·ç‡ï¼‰
        let duration_secs = audio_data.len() as f32 / 16000.0;
        info!("ğŸ¯ [Whisper] Audio duration: {:.2} seconds", duration_secs);

        if duration_secs < 0.1 {
            return Err(WhisperError::AudioTooShort);
        }
        if duration_secs > 600.0 {
            // 10 åˆ†é’Ÿ
            return Err(WhisperError::AudioTooLong);
        }

        // åˆ›å»ºè½¬å½•å‚æ•° - é’ˆå¯¹ä¸­æ–‡ä¼˜åŒ–
        // ä½¿ç”¨ BeamSearch ç­–ç•¥ä»¥æé«˜å‡†ç¡®åº¦ï¼ˆè™½ç„¶ä¼šç¨å¾®æ…¢ä¸€ç‚¹ï¼‰
        let mut params = FullParams::new(SamplingStrategy::BeamSearch {
            beam_size: 5,      // ä½¿ç”¨ 5 ä¸ªå€™é€‰
            patience: -1.0     // é»˜è®¤å€¼
        });

        // è®¾ç½®è¯­è¨€
        info!("ğŸ¯ [Whisper] Language setting: {:?}", language);
        if let Some(lang) = language {
            info!("ğŸ¯ [Whisper] Setting explicit language: {}", lang);
            params.set_language(Some(lang));
            params.set_translate(false);

            // é’ˆå¯¹ä¸­æ–‡çš„ç‰¹æ®Šä¼˜åŒ–
            if lang == "zh" {
                // å¯¹ä¸­æ–‡çš„ç‰¹æ®Šè®¾ç½®
                params.set_temperature(0.0);  // ä½¿ç”¨ç¡®å®šæ€§è§£ç 
                params.set_suppress_blank(true);  // æŠ‘åˆ¶ç©ºç™½è¾“å‡º
                params.set_initial_prompt("ä»¥ä¸‹æ˜¯æ™®é€šè¯çš„å¥å­ã€‚");  // æç¤ºè¿™æ˜¯ä¸­æ–‡
                params.set_single_segment(false);  // å…è®¸å¤šæ®µ
                params.set_print_special(false);  // ä¸æ‰“å°ç‰¹æ®Š token
                params.set_token_timestamps(false); // ä¸éœ€è¦ token æ—¶é—´æˆ³
            }
        } else {
            info!("ğŸ¯ [Whisper] Using auto language detection");
            // å¯¹äºè‡ªåŠ¨æ£€æµ‹ï¼Œæˆ‘ä»¬ä»ç„¶å¯ä»¥è®¾ç½®ä¸€äº›æç¤º
            // Whisper çš„è‡ªåŠ¨æ£€æµ‹æœ‰æ—¶å€™ä¼šåå‘è‹±æ–‡ï¼Œç‰¹åˆ«æ˜¯çŸ­éŸ³é¢‘
            params.set_translate(false);
            params.set_suppress_blank(true);
            // params.set_suppress_non_speech_tokens(true); // æŸäº›ç‰ˆæœ¬å¯èƒ½æ²¡æœ‰è¿™ä¸ªæ–¹æ³•
        }

        // è®¾ç½®çº¿ç¨‹æ•°
        params.set_n_threads(self.n_threads as i32);

        // é€šç”¨ä¼˜åŒ–å‚æ•°
        params.set_print_progress(false);
        params.set_print_realtime(false);
        params.set_print_timestamps(false);
        params.set_print_special(false);  // ä¸æ‰“å°ç‰¹æ®Štoken
        params.set_token_timestamps(false);  // ä¸éœ€è¦ token çº§æ—¶é—´æˆ³

        // åˆ›å»º state å¹¶æ‰§è¡Œè½¬å½•
        let mut state = self.context
            .create_state()
            .map_err(|e| WhisperError::TranscriptionFailed(format!("Failed to create state: {}", e)))?;

        state
            .full(params, audio_data)
            .map_err(|e| WhisperError::TranscriptionFailed(e.to_string()))?;

        // è·å–è½¬å½•ç»“æœ - ä½¿ç”¨è¿­ä»£å™¨æ–¹å¼
        let mut result = String::new();
        let mut segment_count = 0;
        for segment in state.as_iter() {
            let text = segment
                .to_str()
                .map_err(|e| WhisperError::TranscriptionFailed(format!("Failed to get segment text: {:?}", e)))?;
            info!("ğŸ¯ [Whisper] Segment {}: {}", segment_count, text);
            result.push_str(text);
            segment_count += 1;
        }

        let final_result = result.trim().to_string();
        info!("ğŸ¯ [Whisper] Final transcription result: {}", final_result);

        // å»é™¤é¦–å°¾ç©ºæ ¼
        Ok(final_result)
    }

    /// è½¬å½•éŸ³é¢‘å¹¶è¿”å›å¸¦æ—¶é—´æˆ³çš„ç»“æœ
    ///
    /// # å‚æ•°
    /// * `audio_data` - f32 æ ¼å¼çš„éŸ³é¢‘æ•°æ®ï¼ˆ16kHz, å•å£°é“ï¼‰
    /// * `language` - è¯­è¨€ä»£ç ï¼ˆå¦‚ "zh", "en"ï¼‰ï¼ŒNone è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹
    ///
    /// # è¿”å›
    /// è½¬å½•åçš„æ®µè½åˆ—è¡¨ï¼Œæ¯ä¸ªæ®µè½åŒ…å«æ–‡æœ¬å’Œæ—¶é—´æˆ³
    pub fn transcribe_with_timestamps(
        &self,
        audio_data: &[f32],
        language: Option<&str>,
    ) -> Result<Vec<TranscriptionSegment>, WhisperError> {
        // éªŒè¯éŸ³é¢‘æ•°æ®
        validate_audio_data(audio_data)?;

        // åˆ›å»ºè½¬å½•å‚æ•° - é’ˆå¯¹ä¸­æ–‡ä¼˜åŒ–
        // ä½¿ç”¨ BeamSearch ç­–ç•¥ä»¥æé«˜å‡†ç¡®åº¦ï¼ˆè™½ç„¶ä¼šç¨å¾®æ…¢ä¸€ç‚¹ï¼‰
        let mut params = FullParams::new(SamplingStrategy::BeamSearch {
            beam_size: 5,      // ä½¿ç”¨ 5 ä¸ªå€™é€‰
            patience: -1.0     // é»˜è®¤å€¼
        });

        // è®¾ç½®è¯­è¨€
        if let Some(lang) = language {
            params.set_language(Some(lang));
            params.set_translate(false);

            // é’ˆå¯¹ä¸­æ–‡çš„ç‰¹æ®Šä¼˜åŒ–
            if lang == "zh" {
                params.set_temperature(0.0);
                params.set_suppress_blank(true);
                // params.set_suppress_non_speech_tokens(true); // æŸäº›ç‰ˆæœ¬å¯èƒ½æ²¡æœ‰è¿™ä¸ªæ–¹æ³•
            }
        } else {
            params.set_translate(false);
            params.set_suppress_blank(true);
            // params.set_suppress_non_speech_tokens(true); // æŸäº›ç‰ˆæœ¬å¯èƒ½æ²¡æœ‰è¿™ä¸ªæ–¹æ³•
        }

        // è®¾ç½®çº¿ç¨‹æ•°
        params.set_n_threads(self.n_threads as i32);

        // å¯ç”¨æ—¶é—´æˆ³
        params.set_print_timestamps(true);
        params.set_print_special(false);
        params.set_token_timestamps(false);

        // åˆ›å»º state å¹¶æ‰§è¡Œè½¬å½•
        let mut state = self.context
            .create_state()
            .map_err(|e| WhisperError::TranscriptionFailed(format!("Failed to create state: {}", e)))?;

        state
            .full(params, audio_data)
            .map_err(|e| WhisperError::TranscriptionFailed(e.to_string()))?;

        // è·å–è½¬å½•ç»“æœ - ä½¿ç”¨è¿­ä»£å™¨æ–¹å¼
        let mut segments = Vec::new();
        for segment in state.as_iter() {
            let text = segment
                .to_str()
                .map_err(|e| WhisperError::TranscriptionFailed(format!("Failed to get segment text: {:?}", e)))?;

            let start_time = segment.start_timestamp();
            let end_time = segment.end_timestamp();

            segments.push(TranscriptionSegment {
                text: text.trim().to_string(),
                start_ms: start_time as u64 * 10, // whisper æ—¶é—´æˆ³å•ä½æ˜¯å˜ç§’ï¼ˆ10msï¼‰
                end_ms: end_time as u64 * 10,
            });
        }

        Ok(segments)
    }
}

/// è½¬å½•æ®µè½ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct TranscriptionSegment {
    pub text: String,
    pub start_ms: u64,
    pub end_ms: u64,
}

#[cfg(test)]
mod tests {
    use super::*;

    // æ³¨æ„ï¼šè¿™äº›æµ‹è¯•éœ€è¦å®é™…çš„æ¨¡å‹æ–‡ä»¶æ‰èƒ½è¿è¡Œ
    // åœ¨ CI ç¯å¢ƒä¸­å¯èƒ½éœ€è¦è·³è¿‡

    #[test]
    #[ignore] // éœ€è¦æ¨¡å‹æ–‡ä»¶
    fn test_engine_initialization() {
        // è¿™ä¸ªæµ‹è¯•éœ€è¦å®é™…çš„æ¨¡å‹æ–‡ä»¶è·¯å¾„
        let result = WhisperEngine::new("path/to/model.bin");
        // åœ¨æ²¡æœ‰æ¨¡å‹æ–‡ä»¶æ—¶åº”è¯¥è¿”å›é”™è¯¯
        assert!(result.is_err());
    }

    #[test]
    fn test_audio_too_short() {
        // åˆ›å»ºä¸€ä¸ªå¾ˆçŸ­çš„éŸ³é¢‘ï¼ˆå°‘äº 0.1 ç§’ï¼‰
        let short_audio = vec![0.0f32; 1000]; // 0.0625 ç§’ @ 16kHz

        // ä¸éœ€è¦çœŸå®æ¨¡å‹å°±èƒ½æµ‹è¯•éªŒè¯é€»è¾‘
        // è¿™é‡Œæˆ‘ä»¬åªæµ‹è¯•éŸ³é¢‘é•¿åº¦éªŒè¯
        let duration = short_audio.len() as f32 / 16000.0;
        assert!(duration < 0.1);
    }
}
