#!/usr/bin/env python3
"""
FunASR å¸¸é©»æœåŠ¡
ä¿æŒ Python è¿›ç¨‹è¿è¡Œï¼Œæ¨¡å‹åªåŠ è½½ä¸€æ¬¡ï¼Œé€šè¿‡ stdin/stdout è¿›è¡Œ JSON-RPC é€šä¿¡
"""

import sys
import json
import os
from pathlib import Path
from typing import Optional, Dict, Any
from contextlib import contextmanager

@contextmanager
def suppress_stdout():
    """ä¸´æ—¶é‡å®šå‘ stdout åˆ° stderrï¼Œé˜²æ­¢ FunASR è¾“å‡ºæ±¡æŸ“ JSON å“åº”"""
    original_stdout = sys.stdout
    try:
        sys.stdout = sys.stderr
        yield
    finally:
        sys.stdout = original_stdout

# å…¨å±€æ¨¡å‹ç¼“å­˜
_model_cache = {}


def load_model(model_name: str) -> Any:
    """åŠ è½½æˆ–è·å–ç¼“å­˜çš„æ¨¡å‹"""
    if model_name in _model_cache:
        print(f"â™»ï¸  Using cached model: {model_name}", file=sys.stderr)
        return _model_cache[model_name]

    print(f"ğŸ“¦ Loading model: {model_name}", file=sys.stderr)

    try:
        from funasr import AutoModel
    except ImportError as e:
        raise ImportError(f"FunASR not installed: {e}")

    # æ¨¡å‹é…ç½®
    model_configs = {
        "paraformer-zh": {
            "model": "damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
            "vad_model": "damo/speech_fsmn_vad_zh-cn-16k-common-pytorch",
            "punc_model": "damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch",
        },
        "paraformer-large": {
            "model": "iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
            "vad_model": "damo/speech_fsmn_vad_zh-cn-16k-common-pytorch",
            "punc_model": "damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch",
        },
        "sensevoice-small": {
            "model": "iic/SenseVoiceSmall",
            "vad_model": "damo/speech_fsmn_vad_zh-cn-16k-common-pytorch",
            "punc_model": None,
        },
    }

    config = model_configs.get(model_name)
    if not config:
        raise ValueError(f"Unknown model: {model_name}")

    # åˆå§‹åŒ–æ¨¡å‹
    model_kwargs = {
        "model": config["model"],
        "disable_log": True,
        "disable_pbar": True,
        "disable_update": True,
        "hub": "ms",
    }

    if config["vad_model"]:
        model_kwargs["vad_model"] = config["vad_model"]

    if config["punc_model"]:
        model_kwargs["punc_model"] = config["punc_model"]

    # ä½¿ç”¨ suppress_stdout é˜²æ­¢ FunASR è¾“å‡ºæ±¡æŸ“ JSON å“åº”
    with suppress_stdout():
        model = AutoModel(**model_kwargs)

    _model_cache[model_name] = model

    print(f"âœ… Model loaded and cached: {model_name}", file=sys.stderr)
    return model


def transcribe_audio(
    audio_path: str,
    model_name: str = "paraformer-zh",
    language: Optional[str] = None,
    hotword: Optional[str] = None,
) -> Dict[str, Any]:
    """è½¬å½•éŸ³é¢‘"""
    try:
        # éªŒè¯éŸ³é¢‘æ–‡ä»¶
        if not os.path.exists(audio_path):
            return {
                "success": False,
                "error": f"Audio file not found: {audio_path}",
            }

        # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶å¤§å°ï¼ˆè‡³å°‘ 1KBï¼‰
        file_size = os.path.getsize(audio_path)
        print(f"ğŸ“Š Audio file size: {file_size} bytes", file=sys.stderr)

        if file_size < 1000:
            return {
                "success": False,
                "error": f"Audio file too small: {file_size} bytes (minimum 1000 bytes)",
            }

        model = load_model(model_name)

        # å‡†å¤‡è¾“å…¥å‚æ•°
        generate_kwargs = {"input": audio_path}

        if hotword:
            generate_kwargs["hotword"] = hotword

        if language:
            generate_kwargs["language"] = language

        # æ‰§è¡Œè½¬å½•ï¼ˆä½¿ç”¨ suppress_stdout é˜²æ­¢è¾“å‡ºæ±¡æŸ“ï¼‰
        print(f"ğŸ¤ Starting transcription...", file=sys.stderr)
        with suppress_stdout():
            result = model.generate(**generate_kwargs)
        print(f"âœ… Transcription completed", file=sys.stderr)
        print(f"ğŸ“Š Raw result type: {type(result)}", file=sys.stderr)
        print(f"ğŸ“Š Raw result length: {len(result) if result else 0}", file=sys.stderr)
        if result and len(result) > 0:
            print(f"ğŸ“Š First result: {result[0]}", file=sys.stderr)

        if not result or len(result) == 0:
            return {
                "success": False,
                "error": "No transcription result (empty result from model)",
            }

        # æå–æ–‡æœ¬
        text = result[0].get("text", "")

        # å¦‚æœæ–‡æœ¬ä¸ºç©ºï¼Œè¿”å›ç‰¹æ®Šæ¶ˆæ¯
        if not text or text.strip() == "":
            return {
                "success": True,
                "text": "",  # ç©ºæ–‡æœ¬ä¹Ÿç®—æˆåŠŸï¼Œå¯èƒ½æ˜¯é™éŸ³
            }

        return {
            "success": True,
            "text": text,
        }

    except RuntimeError as e:
        error_msg = str(e)
        if "stack expects a non-empty TensorList" in error_msg:
            return {
                "success": False,
                "error": "éŸ³é¢‘å¤ªçŸ­æˆ–ä¸ºé™éŸ³ï¼Œæ— æ³•è¯†åˆ«ã€‚è¯·å½•åˆ¶æ›´é•¿çš„éŸ³é¢‘ï¼ˆè‡³å°‘1ç§’ï¼‰ã€‚",
            }
        else:
            import traceback
            error_details = traceback.format_exc()
            print(f"âŒ Runtime error:\\n{error_details}", file=sys.stderr)
            return {
                "success": False,
                "error": f"è½¬å½•å¤±è´¥: {error_msg}",
            }
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"âŒ Transcription error:\\n{error_details}", file=sys.stderr)
        return {
            "success": False,
            "error": f"è½¬å½•å¤±è´¥: {str(e)}",
        }


def handle_request(request: Dict[str, Any]) -> Dict[str, Any]:
    """å¤„ç†å•ä¸ªè¯·æ±‚"""
    method = request.get("method")
    params = request.get("params", {})

    if method == "transcribe":
        return transcribe_audio(
            audio_path=params.get("audio_path"),
            model_name=params.get("model_name", "paraformer-zh"),
            language=params.get("language"),
            hotword=params.get("hotword"),
        )
    elif method == "ping":
        return {"success": True, "message": "pong"}
    elif method == "shutdown":
        return {"success": True, "message": "shutting down"}
    else:
        return {
            "success": False,
            "error": f"Unknown method: {method}",
        }


def main():
    """ä¸»å¾ªç¯ï¼šè¯»å– stdin çš„ JSON è¯·æ±‚ï¼Œè¾“å‡º JSON å“åº”"""
    print("ğŸš€ FunASR Server started", file=sys.stderr)
    print(f"ğŸ Python: {sys.executable}", file=sys.stderr)
    print(f"ğŸ Version: {sys.version}", file=sys.stderr)

    # ç¡®ä¿ stdout ç«‹å³åˆ·æ–°
    sys.stdout.reconfigure(line_buffering=True)

    while True:
        try:
            # è¯»å–ä¸€è¡Œ JSON è¯·æ±‚
            line = sys.stdin.readline()
            if not line:
                break

            line = line.strip()
            if not line:
                continue

            # è§£æè¯·æ±‚
            request = json.loads(line)
            print(f"ğŸ“¨ Received request: {request.get('method')}", file=sys.stderr)

            # å¤„ç†è¯·æ±‚
            response = handle_request(request)

            # è¾“å‡ºå“åº”ï¼ˆå•è¡Œ JSONï¼‰
            print(json.dumps(response, ensure_ascii=False), flush=True)

            # å¦‚æœæ˜¯ shutdown å‘½ä»¤ï¼Œé€€å‡º
            if request.get("method") == "shutdown":
                break

        except json.JSONDecodeError as e:
            error_response = {
                "success": False,
                "error": f"Invalid JSON: {str(e)}",
            }
            print(json.dumps(error_response, ensure_ascii=False), flush=True)
        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
            print(f"âŒ Error processing request:\\n{error_details}", file=sys.stderr)
            error_response = {
                "success": False,
                "error": f"Server error: {str(e)}",
            }
            print(json.dumps(error_response, ensure_ascii=False), flush=True)

    print("ğŸ‘‹ FunASR Server stopped", file=sys.stderr)


if __name__ == "__main__":
    main()
